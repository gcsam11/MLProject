{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_missing_values(df):\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_data = missing_data[missing_data > 0]\n",
    "    return missing_data.sort_values(ascending=False)\n",
    "\n",
    "def detect_outliers(df, columns):\n",
    "    outliers = {}\n",
    "    for column in columns:\n",
    "            # Use IQR method\n",
    "            Q1 = df[column].quantile(0.25)\n",
    "            Q3 = df[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outlier_rows = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "            outliers[column] = outlier_rows[[column]]\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "def detect_duplicates(df):\n",
    "    duplicate_rows = df[df.duplicated()]\n",
    "    return duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped redundant rebound columns and renamed others for clarity.\n",
      "Dropped 'divID' column as it contains no information.\n",
      "Dropped 'seeded' column as it contains only zero values.\n",
      "Dropped 'lgID', 'franchID', 'confID', 'name', and 'arena' as they are irrelevant for predictive modeling.\n"
     ]
    }
   ],
   "source": [
    "# Load the teams_post data\n",
    "teams = pd.read_csv('./data/teams.csv')\n",
    "\n",
    "# Convert 'playoff' column to binary (1 for 'Y', 0 for 'N')\n",
    "teams['playoff'] = teams['playoff'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "zero_cols = [\"tmORB\", \"tmDRB\", \"tmTRB\", \"opptmORB\", \"opptmDRB\", \"opptmTRB\"]\n",
    "\n",
    "# Since \"tmORB\", \"tmDRB\", \"tmTRB\", \"opptmORB\", \"opptmDRB\", and \"opptmTRB\" contain only zero values,\n",
    "# and are redundant with \"o_oreb\", \"o_dreb\", \"o_reb\" for team stats, and \"d_oreb\", \"d_dreb\", \"d_reb\" for opponent stats,\n",
    "# we drop the redundant columns.\n",
    "\n",
    "teams = teams.drop(columns=zero_cols)\n",
    "print(\"Dropped redundant rebound columns and renamed others for clarity.\")\n",
    "\n",
    "# Drop the 'divID' column as it contains only empty strings and does not add useful information\n",
    "teams = teams.drop(columns=['divID'])\n",
    "print(\"Dropped 'divID' column as it contains no information.\")\n",
    "\n",
    "# Drop the 'seeded' column as it contains only zero values\n",
    "teams = teams.drop(columns=['seeded'])\n",
    "print(\"Dropped 'seeded' column as it contains only zero values.\")\n",
    "\n",
    "def calculate_playoff_score(row):\n",
    "    if row['finals'] == 'W':\n",
    "        return 4  # Won the championship\n",
    "    elif row['finals'] == 'L':\n",
    "        return 3  # Lost in the finals\n",
    "    elif row['semis'] == 'L':\n",
    "        return 2  # Lost in the semifinals\n",
    "    elif row['firstRound'] == 'L':\n",
    "        return 1  # Lost in the first round\n",
    "    else:\n",
    "        return 0  # Did not make the playoffs\n",
    "\n",
    "# Apply the function to each row to create the playoff_progression_score\n",
    "teams['playoff_progression_score'] = teams.apply(calculate_playoff_score, axis=1)\n",
    "\n",
    "# Drop the original 'firstRound', 'semis', and 'finals' columns as they are now redundant\n",
    "teams = teams.drop(columns=['firstRound', 'semis', 'finals'])\n",
    "\n",
    "# Drop columns that don't add predictive value\n",
    "# 'lgID': Contains only \"WNBA\" for every row, so it provides no additional information.\n",
    "# 'franchID': Redundant identifier, as 'tmID' already identifies each team uniquely.\n",
    "# 'confID': Lacks value without conference-specific qualification/matchup data.\n",
    "# 'name': Purely descriptive and irrelevant to playoff predictions.\n",
    "# 'arena': Also descriptive and does not impact playoff qualification.\n",
    "teams = teams.drop(columns=['lgID', 'franchID', 'confID', 'name', 'arena'])\n",
    "print(\"Dropped 'lgID', 'franchID', 'confID', 'name', and 'arena' as they are irrelevant for predictive modeling.\")\n",
    "\n",
    "## DETECTION OF MISSING VALUES\n",
    "#missing_values = detect_missing_values(teams)\n",
    "#print(\"\\nMissing Values\")\n",
    "#print(missing_values)\n",
    "#\n",
    "## DETECTION OF DUPLICATES\n",
    "#duplicate_rows = detect_duplicates(teams)\n",
    "#print(\"\\nDuplicates\")\n",
    "#print(duplicate_rows)\n",
    "#\n",
    "## DETECTION OF OUTLIERS\n",
    "## Select numerical columns only\n",
    "#numeric_columns = teams.select_dtypes(include=['float64', 'int64']).columns\n",
    "#\n",
    "#for column in numeric_columns:\n",
    "#    plt.figure(figsize=(8, 4))\n",
    "#    sns.boxplot(x=teams[column])\n",
    "#    plt.title(f'Box Plot of {column}')\n",
    "#    plt.show()\n",
    "#\n",
    "#outliers = detect_outliers(teams, numeric_columns)\n",
    "#\n",
    "#for col, outlier_data in outliers.items():\n",
    "#    print(f\"Outliers in {col}:\\n{outlier_data}\\n\")\n",
    "#\n",
    "## Plot for 'next_season_playoff' column\n",
    "#plt.figure(figsize=(6, 4))\n",
    "#plt.bar(next_playoff_counts.index, next_playoff_counts.values)\n",
    "#plt.title('Data Balance in Next Season Playoff')\n",
    "#plt.xlabel('Next Season Playoff (0 = No, 1 = Yes)')\n",
    "#plt.ylabel('Count')\n",
    "#plt.xticks([0, 1])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>year</th>\n",
       "      <th>stint</th>\n",
       "      <th>tmID</th>\n",
       "      <th>GP</th>\n",
       "      <th>GS</th>\n",
       "      <th>minutes</th>\n",
       "      <th>points</th>\n",
       "      <th>oRebounds</th>\n",
       "      <th>dRebounds</th>\n",
       "      <th>...</th>\n",
       "      <th>PostBlocks</th>\n",
       "      <th>PostTurnovers</th>\n",
       "      <th>PostPF</th>\n",
       "      <th>PostfgAttempted</th>\n",
       "      <th>PostfgMade</th>\n",
       "      <th>PostftAttempted</th>\n",
       "      <th>PostftMade</th>\n",
       "      <th>PostthreeAttempted</th>\n",
       "      <th>PostthreeMade</th>\n",
       "      <th>PostDQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     playerID  year stint tmID    GP    GS  minutes  points  oRebounds  \\\n",
       "0  abrossv01w     2     0  MIN  26.0  23.0    846.0   343.0       43.0   \n",
       "1  abrossv01w     3     0  MIN  27.0  27.0    805.0   314.0       45.0   \n",
       "2  abrossv01w     4     0  MIN  30.0  25.0    792.0   318.0       44.0   \n",
       "3  abrossv01w     5     0  MIN  22.0  11.0    462.0   146.0       17.0   \n",
       "4  abrossv01w     6     0  MIN  31.0  31.0    777.0   304.0       29.0   \n",
       "\n",
       "   dRebounds  ...  PostBlocks  PostTurnovers  PostPF  PostfgAttempted  \\\n",
       "0      131.0  ...         0.0            0.0     0.0              0.0   \n",
       "1      101.0  ...         0.0            0.0     0.0              0.0   \n",
       "2       97.0  ...         1.0            8.0     8.0             22.0   \n",
       "3       57.0  ...         2.0            3.0     7.0             23.0   \n",
       "4       78.0  ...         0.0            0.0     0.0              0.0   \n",
       "\n",
       "   PostfgMade  PostftAttempted  PostftMade  PostthreeAttempted  PostthreeMade  \\\n",
       "0         0.0              0.0         0.0                 0.0            0.0   \n",
       "1         0.0              0.0         0.0                 0.0            0.0   \n",
       "2         6.0              8.0         8.0                 7.0            3.0   \n",
       "3         8.0              4.0         2.0                 8.0            2.0   \n",
       "4         0.0              0.0         0.0                 0.0            0.0   \n",
       "\n",
       "   PostDQ  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the players_teams data\n",
    "players_teams = pd.read_csv(\"./data/players_teams.csv\")\n",
    "\n",
    "# Drop 'lgID' as it contains only \"WNBA\" and provides no unique value\n",
    "players_teams = players_teams.drop(columns=['lgID'])\n",
    "\n",
    "# Detect and drop duplicates\n",
    "duplicates = players_teams[players_teams.duplicated()]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates detected. Removing duplicate rows.\")\n",
    "    players_teams = players_teams.drop_duplicates()\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# Display a sample of the dataframe to verify changes\n",
    "display(players_teams.head())\n",
    "\n",
    "# Store cleaned csv\n",
    "players_teams.to_csv('./cleaned_data/players_teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in 'firstseason' are 0: True\n",
      "All values in 'lastseason' are 0: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioID</th>\n",
       "      <th>pos</th>\n",
       "      <th>firstseason</th>\n",
       "      <th>lastseason</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>college</th>\n",
       "      <th>collegeOther</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>deathDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>dydekma01w</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1974-04-28</td>\n",
       "      <td>2011-05-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bioID pos  firstseason  lastseason  height  weight college  \\\n",
       "225  dydekma01w   C            0           0     9.0     223     NaN   \n",
       "\n",
       "    collegeOther   birthDate   deathDate  \n",
       "225          NaN  1974-04-28  2011-05-27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 'firstseason', 'lastseason', and 'deathDate' columns as they contain only irrelevant values.\n",
      "No duplicates found.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioID</th>\n",
       "      <th>pos</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>college</th>\n",
       "      <th>collegeOther</th>\n",
       "      <th>birthDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>F</td>\n",
       "      <td>74.0</td>\n",
       "      <td>169</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adairje01w</td>\n",
       "      <td>C</td>\n",
       "      <td>76.0</td>\n",
       "      <td>197</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adamsda01w</td>\n",
       "      <td>F-C</td>\n",
       "      <td>73.0</td>\n",
       "      <td>239</td>\n",
       "      <td>Texas A&amp;M</td>\n",
       "      <td>Jefferson College (JC)</td>\n",
       "      <td>1989-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adamsjo01w</td>\n",
       "      <td>C</td>\n",
       "      <td>75.0</td>\n",
       "      <td>180</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aguilel01w</td>\n",
       "      <td>G</td>\n",
       "      <td>67.0</td>\n",
       "      <td>165</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-10-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bioID  pos  height  weight            college            collegeOther  \\\n",
       "1  abrossv01w    F    74.0     169        Connecticut                     NaN   \n",
       "2  adairje01w    C    76.0     197  George Washington                     NaN   \n",
       "3  adamsda01w  F-C    73.0     239          Texas A&M  Jefferson College (JC)   \n",
       "4  adamsjo01w    C    75.0     180         New Mexico                     NaN   \n",
       "8  aguilel01w    G    67.0     165  George Washington                     NaN   \n",
       "\n",
       "    birthDate  \n",
       "1  1980-07-09  \n",
       "2  1986-12-19  \n",
       "3  1989-02-19  \n",
       "4  1981-05-24  \n",
       "8  1976-10-15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the players data\n",
    "players = pd.read_csv(\"./data/players.csv\")\n",
    "\n",
    "# Filter out rows in players that do not have corresponding playerIDs in players_teams\n",
    "valid_player_ids = players_teams['playerID'].unique()\n",
    "players = players[players['bioID'].isin(valid_player_ids)]\n",
    "\n",
    "# Show that all values in firstseason and lastseason are '0'\n",
    "firstseason_all_zero = (players['firstseason'] == 0).all()\n",
    "lastseason_all_zero = (players['lastseason'] == 0).all()\n",
    "\n",
    "print(\"All values in 'firstseason' are 0:\", firstseason_all_zero)\n",
    "print(\"All values in 'lastseason' are 0:\", lastseason_all_zero)\n",
    "\n",
    "# Show the only valida player with a registered Death Date\n",
    "non_zero_death_dates = players[players['deathDate'] != \"0000-00-00\"]\n",
    "display(non_zero_death_dates.head())\n",
    "\n",
    "# Even though there is 1 registered Death Date, it really doesn't add anything. Birth Date is kept, for potential aging information.\n",
    "players = players.drop(columns=['firstseason', 'lastseason', 'deathDate'])\n",
    "print(\"Dropped 'firstseason', 'lastseason', and 'deathDate' columns as they contain only irrelevant values.\")\n",
    "\n",
    "# Detect and drop duplicates\n",
    "duplicates = players[players.duplicated()]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates detected. Removing duplicate rows.\")\n",
    "    players = players.drop_duplicates()\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# Display a sample of the dataframe to verify changes\n",
    "display(players.head())\n",
    "\n",
    "# Store cleaned csv\n",
    "players.to_csv('./cleaned_data/players.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found in player awards.\n",
      "No duplicates found in coach awards.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>award</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thompti01w</td>\n",
       "      <td>All-Star Game MVP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leslili01w</td>\n",
       "      <td>All-Star Game MVP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leslili01w</td>\n",
       "      <td>All-Star Game MVP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teaslni01w</td>\n",
       "      <td>All-Star Game MVP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swoopsh01w</td>\n",
       "      <td>All-Star Game MVP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     playerID              award  year\n",
       "0  thompti01w  All-Star Game MVP     1\n",
       "1  leslili01w  All-Star Game MVP     2\n",
       "2  leslili01w  All-Star Game MVP     3\n",
       "3  teaslni01w  All-Star Game MVP     4\n",
       "4  swoopsh01w  All-Star Game MVP     6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coachID</th>\n",
       "      <th>award</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coopemi01w</td>\n",
       "      <td>Coach of the Year</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hugheda99w</td>\n",
       "      <td>Coach of the Year</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stanlma99w</td>\n",
       "      <td>Coach of the Year</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>laimbbi01w</td>\n",
       "      <td>Coach of the Year</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mcconsu01w</td>\n",
       "      <td>Coach of the Year</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coachID              award  year\n",
       "8   coopemi01w  Coach of the Year     1\n",
       "9   hugheda99w  Coach of the Year     2\n",
       "10  stanlma99w  Coach of the Year     3\n",
       "11  laimbbi01w  Coach of the Year     4\n",
       "12  mcconsu01w  Coach of the Year     5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the awards_players data\n",
    "awards_players = pd.read_csv(\"./data/awards_players.csv\")\n",
    "\n",
    "# Drop 'lgID' column as it provides no unique value\n",
    "awards_players = awards_players.drop(columns=['lgID'])\n",
    "\n",
    "# Separate dataframes for player awards and coach awards\n",
    "player_awards = awards_players[~awards_players['award'].str.contains(\"Coach\")].copy()\n",
    "coach_awards = awards_players[awards_players['award'].str.contains(\"Coach\")].copy()\n",
    "\n",
    "# Standardize award names\n",
    "award_name_mapping = {\n",
    "    \"Kim Perrot Sportsmanship\": \"Kim Perrot Sportsmanship Award\",\n",
    "    \"Kim Perrot Sportsmanship Award\": \"Kim Perrot Sportsmanship Award\",\n",
    "    \"All-Star Game Most Valuable Player\": \"All-Star Game MVP\",\n",
    "    \"Most Valuable Player\": \"MVP\",\n",
    "    \"WNBA Finals Most Valuable Player\": \"Finals MVP\",\n",
    "    \"Sixth Woman of the Year\": \"6th Woman of the Year\",\n",
    "    \"WNBA All-Decade Team\": \"All-Decade Team\",\n",
    "    \"WNBA All Decade Team Honorable Mention\": \"All-Decade Team Honorable Mention\"\n",
    "}\n",
    "\n",
    "player_awards.loc[:, 'award'] = player_awards['award'].map(award_name_mapping).fillna(player_awards['award'])\n",
    "coach_awards.loc[:, 'award'] = coach_awards['award'].map(award_name_mapping).fillna(coach_awards['award'])\n",
    "\n",
    "# Detect and drop duplicates\n",
    "duplicates_player = player_awards[player_awards.duplicated()]\n",
    "if not duplicates_player.empty:\n",
    "    print(\"Duplicates detected in player awards. Removing duplicate rows.\")\n",
    "    player_awards = player_awards.drop_duplicates()\n",
    "else:\n",
    "    print(\"No duplicates found in player awards.\")\n",
    "\n",
    "duplicates_coach = coach_awards[coach_awards.duplicated()]\n",
    "if not duplicates_coach.empty:\n",
    "    print(\"Duplicates detected in coach awards. Removing duplicate rows.\")\n",
    "    coach_awards = coach_awards.drop_duplicates()\n",
    "else:\n",
    "    print(\"No duplicates found in coach awards.\")\n",
    "\n",
    "# Swap 'playerID' for 'coachID' in coach awards\n",
    "coach_awards = coach_awards.rename(columns={'playerID': 'coachID'})\n",
    "\n",
    "# Display samples of both dataframes to verify transformations\n",
    "display(player_awards.head())\n",
    "display(coach_awards.head())\n",
    "\n",
    "# Store cleaned csvs\n",
    "player_awards.to_csv('./cleaned_data/player_awards.csv', index=False)\n",
    "coach_awards.to_csv('./cleaned_data/coach_awards.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coachID</th>\n",
       "      <th>year</th>\n",
       "      <th>tmID</th>\n",
       "      <th>stint</th>\n",
       "      <th>won</th>\n",
       "      <th>lost</th>\n",
       "      <th>post_wins</th>\n",
       "      <th>post_losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adamsmi01w</td>\n",
       "      <td>5</td>\n",
       "      <td>WAS</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adubari99w</td>\n",
       "      <td>1</td>\n",
       "      <td>NYL</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adubari99w</td>\n",
       "      <td>2</td>\n",
       "      <td>NYL</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adubari99w</td>\n",
       "      <td>3</td>\n",
       "      <td>NYL</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adubari99w</td>\n",
       "      <td>4</td>\n",
       "      <td>NYL</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coachID  year tmID  stint   won  lost  post_wins  post_losses\n",
       "0  adamsmi01w     5  WAS      0  17.0  17.0        1.0          2.0\n",
       "1  adubari99w     1  NYL      0  20.0  12.0        4.0          3.0\n",
       "2  adubari99w     2  NYL      0  21.0  11.0        3.0          3.0\n",
       "3  adubari99w     3  NYL      0  18.0  14.0        4.0          4.0\n",
       "4  adubari99w     4  NYL      0  16.0  18.0        0.0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the coaches data\n",
    "coaches = pd.read_csv(\"./data/coaches.csv\")\n",
    "\n",
    "# Drop 'lgID' as it is only \"WNBA\" and provides no unique value\n",
    "coaches = coaches.drop(columns=['lgID'])\n",
    "\n",
    "# Detect and drop duplicates\n",
    "duplicates = coaches[coaches.duplicated()]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates detected. Removing duplicate rows.\")\n",
    "    coaches = coaches.drop_duplicates()\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# Display a sample of the dataframe to verify changes\n",
    "display(coaches.head())\n",
    "\n",
    "coaches.to_csv('./cleaned_data/coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Playoff</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "      <th>PlayoffProgScore</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>WIN%</th>\n",
       "      <th>MIN</th>\n",
       "      <th>...</th>\n",
       "      <th>AST RATIO</th>\n",
       "      <th>OREB%</th>\n",
       "      <th>DREB%</th>\n",
       "      <th>REB%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>EFG%</th>\n",
       "      <th>TS%</th>\n",
       "      <th>PACE</th>\n",
       "      <th>AvgPIE_NextYearPlayers</th>\n",
       "      <th>CER_NextYearCoach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>6825.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.075514</td>\n",
       "      <td>5.647841</td>\n",
       "      <td>12.952548</td>\n",
       "      <td>9.197267</td>\n",
       "      <td>18.706625</td>\n",
       "      <td>44.109832</td>\n",
       "      <td>49.165697</td>\n",
       "      <td>79.763058</td>\n",
       "      <td>0.118533</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>52.941176</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.169890</td>\n",
       "      <td>6.595918</td>\n",
       "      <td>14.155629</td>\n",
       "      <td>10.349363</td>\n",
       "      <td>17.610889</td>\n",
       "      <td>47.199341</td>\n",
       "      <td>51.825955</td>\n",
       "      <td>82.113185</td>\n",
       "      <td>0.104153</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.373637</td>\n",
       "      <td>6.295150</td>\n",
       "      <td>13.179916</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>18.696662</td>\n",
       "      <td>46.111403</td>\n",
       "      <td>50.675049</td>\n",
       "      <td>69.826695</td>\n",
       "      <td>0.102416</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CHA</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.368024</td>\n",
       "      <td>7.054795</td>\n",
       "      <td>13.001017</td>\n",
       "      <td>10.199032</td>\n",
       "      <td>19.064320</td>\n",
       "      <td>46.207865</td>\n",
       "      <td>51.060468</td>\n",
       "      <td>64.240053</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CHA</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>6450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.433293</td>\n",
       "      <td>6.550976</td>\n",
       "      <td>13.776371</td>\n",
       "      <td>10.213904</td>\n",
       "      <td>16.387385</td>\n",
       "      <td>48.910615</td>\n",
       "      <td>53.825683</td>\n",
       "      <td>65.632452</td>\n",
       "      <td>0.101880</td>\n",
       "      <td>0.238421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Playoff Team  Year  Rank  PlayoffProgScore    GP     W     L       WIN%  \\\n",
       "0      0.0  ATL     9   7.0               0.0  34.0   4.0  30.0  11.764706   \n",
       "1      1.0  ATL    10   2.0               1.0  34.0  18.0  16.0  52.941176   \n",
       "2      0.0  CHA     1   8.0               0.0  32.0   8.0  24.0  25.000000   \n",
       "3      1.0  CHA     2   4.0               3.0  32.0  18.0  14.0  56.250000   \n",
       "4      1.0  CHA     3   2.0               1.0  32.0  18.0  14.0  56.250000   \n",
       "\n",
       "      MIN  ...  AST RATIO     OREB%      DREB%       REB%       TOV%  \\\n",
       "0  6825.0  ...  18.075514  5.647841  12.952548   9.197267  18.706625   \n",
       "1  6950.0  ...  19.169890  6.595918  14.155629  10.349363  17.610889   \n",
       "2  6475.0  ...  24.373637  6.295150  13.179916   9.714286  18.696662   \n",
       "3  6500.0  ...  22.368024  7.054795  13.001017  10.199032  19.064320   \n",
       "4  6450.0  ...  23.433293  6.550976  13.776371  10.213904  16.387385   \n",
       "\n",
       "        EFG%        TS%       PACE  AvgPIE_NextYearPlayers  CER_NextYearCoach  \n",
       "0  44.109832  49.165697  79.763058                0.118533           0.040000  \n",
       "1  47.199341  51.825955  82.113185                0.104153           0.490000  \n",
       "2  46.111403  50.675049  69.826695                0.102416           0.090000  \n",
       "3  46.207865  51.060468  64.240053                0.085999           0.320000  \n",
       "4  48.910615  53.825683  65.632452                0.101880           0.238421  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 10 stats saved to ./cleaned_data/year_10_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics for the new dataframe\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "# Team Statistics\n",
    "dataset['Playoff'] = teams['playoff']\n",
    "dataset['Team'] = teams['tmID']\n",
    "dataset['Year'] = teams['year']\n",
    "dataset['Rank'] = teams['rank']\n",
    "dataset['PlayoffProgScore'] = teams['playoff_progression_score']\n",
    "dataset['GP'] = teams['GP']\n",
    "dataset['W'] = teams['won']\n",
    "dataset['L'] = teams['lost']\n",
    "dataset['WIN%'] = 100 * (teams['won'] / teams['GP'])\n",
    "dataset['MIN'] = teams['min']\n",
    "dataset['PTS'] = teams['o_pts']\n",
    "dataset['FGM'] = teams['o_fgm']\n",
    "dataset['FGA'] = teams['o_fga']\n",
    "dataset['FG%'] = 100 * (teams['o_fgm'] / teams['o_fga'])\n",
    "dataset['3PM'] = teams['o_3pm']\n",
    "dataset['3PA'] = teams['o_3pa']\n",
    "dataset['3P%'] = 100 * (teams['o_3pm'] / teams['o_3pa'])\n",
    "dataset['FTM'] = teams['o_ftm']\n",
    "dataset['FTA'] = teams['o_fta']\n",
    "dataset['FT%'] = 100 * (teams['o_ftm'] / teams['o_fta'])\n",
    "dataset['OREB'] = teams['o_oreb']\n",
    "dataset['DREB'] = teams['o_dreb']\n",
    "dataset['REB'] = teams['o_reb']\n",
    "dataset['AST'] = teams['o_asts']\n",
    "dataset['TOV'] = teams['o_to']\n",
    "dataset['STL'] = teams['o_stl']\n",
    "dataset['BLK'] = teams['o_blk']\n",
    "dataset['BLKA'] = teams['d_blk']\n",
    "dataset['PF'] = teams['o_pf']\n",
    "dataset['PFD'] = teams['d_pf']\n",
    "\n",
    "# Advanced\n",
    "dataset['POSS'] = 0.5 * (\n",
    "    (teams['o_fga'] + 0.4 * teams['o_fta'] -\n",
    "     1.07 * (teams['o_oreb'] / (teams['o_oreb'] + teams['d_dreb'])) *\n",
    "     (teams['o_fga'] - teams['o_fgm']) + teams['o_to']) +\n",
    "    (teams['d_fga'] + 0.4 * teams['d_fta'] -\n",
    "     1.07 * (teams['d_oreb'] / (teams['d_oreb'] + teams['o_dreb'])) *\n",
    "     (teams['d_fga'] - teams['d_fgm']) + teams['d_to'])\n",
    ")\n",
    "dataset['OFFRTG'] = 100 * (teams['o_pts'] / dataset['POSS'])\n",
    "dataset['DEFRTG'] = 100 * (teams['d_pts'] / dataset['POSS'])\n",
    "dataset['NETRTG'] = dataset['OFFRTG'] - dataset['DEFRTG']\n",
    "dataset['AST/TO'] = teams['o_asts'] / teams['o_to']\n",
    "dataset['AST RATIO'] = (teams['o_asts'] * 100) / dataset['POSS']\n",
    "dataset['OREB%'] = (\n",
    "    100 * (teams['o_oreb'] * (dataset['MIN'] / 5)) / \n",
    "    (dataset['MIN'] * (teams['o_oreb'] + teams['d_dreb']))\n",
    ")\n",
    "dataset['DREB%'] = (\n",
    "    100 * (teams['o_dreb'] * (dataset['MIN'] / 5)) / \n",
    "    (dataset['MIN'] * (teams['o_dreb'] + teams['d_oreb']))\n",
    ")\n",
    "dataset['REB%'] = (\n",
    "    100 * (teams['o_reb'] * (dataset['MIN'] / 5)) / \n",
    "    (dataset['MIN'] * (teams['o_reb'] + teams['d_reb']))\n",
    ")\n",
    "dataset['TOV%'] = 100 * teams['o_to'] / (\n",
    "    teams['o_fga'] + 0.44 * teams['o_fta'] + teams['o_to']\n",
    ")\n",
    "dataset['EFG%'] = 100 * ((teams['o_fgm'] + (0.5 * teams['o_3pm'])) / teams['o_fga'])\n",
    "dataset['TS%'] = 100 * (teams['o_pts'] / (2 * (teams['o_fga'] + 0.44 * teams['o_fta'])))\n",
    "\n",
    "OPPPOSS = 0.5 * (\n",
    "    (teams['d_fga'] + 0.4 * teams['d_fta'] -\n",
    "     1.07 * (teams['d_oreb'] / (teams['d_oreb'] + teams['o_dreb'])) *\n",
    "     (teams['d_fga'] - teams['d_fgm']) + teams['d_to']) +\n",
    "    (teams['o_fga'] + 0.4 * teams['o_fta'] -\n",
    "     1.07 * (teams['o_oreb'] / (teams['o_oreb'] + teams['d_dreb'])) *\n",
    "     (teams['o_fga'] - teams['o_fgm']) + teams['o_to'])\n",
    ")\n",
    "dataset['PACE'] = 40 * ((dataset['POSS'] + OPPPOSS) / (2 * (dataset['MIN'] / 5)))\n",
    "\n",
    "# Rename player stats columns to match team stats naming convention\n",
    "players_teams = players_teams.rename(columns={\n",
    "    'points': 'PTS',\n",
    "    'fgMade': 'FGM',\n",
    "    'ftMade': 'FTM',\n",
    "    'fgAttempted': 'FGA',\n",
    "    'ftAttempted': 'FTA',\n",
    "    'dRebounds': 'DREB',\n",
    "    'oRebounds': 'OREB',\n",
    "    'assists': 'AST',\n",
    "    'steals': 'STL',\n",
    "    'blocks': 'BLK',\n",
    "    'PF': 'PF',\n",
    "    'turnovers': 'TOV'\n",
    "})\n",
    "\n",
    "# Merge player and team datasets on team ID and year\n",
    "merged_data = players_teams.merge(\n",
    "    dataset,\n",
    "    left_on=['tmID', 'year'],\n",
    "    right_on=['Team', 'Year'],\n",
    "    suffixes=('', '_team')\n",
    ")\n",
    "\n",
    "# Calculate GmStats as a proportion of team stats\n",
    "merged_data['games_ratio'] = merged_data['GP'] / merged_data['GP_team']\n",
    "\n",
    "# Define game-level stats for players\n",
    "team_stat_columns = [\n",
    "    'PTS', 'FGM', 'FTM', 'FGA', 'FTA', 'DREB', 'OREB', 'AST', 'STL', 'BLK', 'PF', 'TOV'\n",
    "]\n",
    "\n",
    "for stat in team_stat_columns:\n",
    "    merged_data[f'Gm{stat}'] = merged_data['games_ratio'] * merged_data[f'{stat}_team']\n",
    "\n",
    "# Calculate PIE for each player\n",
    "merged_data['PIE'] = (\n",
    "    merged_data['PTS'] + \n",
    "    merged_data['FGM'] + \n",
    "    merged_data['FTM'] - \n",
    "    merged_data['FGA'] - \n",
    "    merged_data['FTA'] + \n",
    "    merged_data['DREB'] + \n",
    "    (0.5 * merged_data['OREB']) + \n",
    "    merged_data['AST'] + \n",
    "    merged_data['STL'] + \n",
    "    (0.5 * merged_data['BLK']) - \n",
    "    merged_data['PF'] - \n",
    "    merged_data['TOV']\n",
    ") / (\n",
    "    merged_data['GmPTS'] + \n",
    "    merged_data['GmFGM'] + \n",
    "    merged_data['GmFTM'] - \n",
    "    merged_data['GmFGA'] - \n",
    "    merged_data['GmFTA'] + \n",
    "    merged_data['GmDREB'] + \n",
    "    (0.5 * merged_data['GmOREB']) + \n",
    "    merged_data['GmAST'] + \n",
    "    merged_data['GmSTL'] + \n",
    "    (0.5 * merged_data['GmBLK']) - \n",
    "    merged_data['GmPF'] - \n",
    "    merged_data['GmTOV']\n",
    ")\n",
    "\n",
    "# Average PIE for players with multiple stints in the same year\n",
    "merged_data = merged_data.groupby(['playerID', 'year'], as_index=False).agg({\n",
    "    'PIE': 'mean',\n",
    "    'tmID': 'first',  # Retain the first team ID for simplicity\n",
    "    'games_ratio': 'sum'  # Sum games ratio to ensure accurate contribution\n",
    "})\n",
    "\n",
    "coaches_cer = pd.read_csv('./cleaned_data/coaches_ema.csv')\n",
    "\n",
    "# Step 1: Ensure unique team-year combinations in 'dataset'\n",
    "dataset_unique = dataset.drop_duplicates(subset=['Team', 'Year'])\n",
    "\n",
    "# Step 2: Create dictionaries for quick access\n",
    "pie_dict = merged_data.set_index(['playerID', 'year'])['PIE'].to_dict()\n",
    "coach_cer_dict = coaches_cer.set_index(['coachID', 'year'])['CER'].to_dict()\n",
    "coach_dict = coaches.set_index(['tmID', 'year'])['coachID'].to_dict()\n",
    "\n",
    "# Create dictionaries of all years available for coaches and players\n",
    "coach_years = {}\n",
    "for coach_id, year in coach_cer_dict.keys():\n",
    "    if coach_id not in coach_years:\n",
    "        coach_years[coach_id] = []\n",
    "    coach_years[coach_id].append(year)\n",
    "\n",
    "player_years = {}\n",
    "for pid, year in pie_dict.keys():\n",
    "    if pid not in player_years:\n",
    "        player_years[pid] = []\n",
    "    player_years[pid].append(year)\n",
    "\n",
    "# Calculate yearly averages\n",
    "yearly_avg_cer = coaches_cer.groupby('year')['CER'].mean().to_dict()\n",
    "yearly_avg_pie = merged_data.groupby('year')['PIE'].mean().to_dict()\n",
    "\n",
    "# Initialize new columns with None\n",
    "dataset['AvgPIE_NextYearPlayers'] = None\n",
    "dataset['CER_NextYearCoach'] = None\n",
    "\n",
    "# Process each team-year combination\n",
    "for index, row in dataset.iterrows():\n",
    "    team = row['Team']\n",
    "    year = row['Year']\n",
    "    next_year = year + 1\n",
    "    \n",
    "    # Get next year's coach and their CER\n",
    "    next_year_coach = coach_dict.get((team, next_year))\n",
    "    current_year_cer = None\n",
    "    \n",
    "    if next_year_coach:\n",
    "        # Try to get current year CER\n",
    "        current_year_cer = coach_cer_dict.get((next_year_coach, year))\n",
    "        \n",
    "        if current_year_cer is None and next_year_coach in coach_years:\n",
    "            # If no current year CER, find the most recent previous CER\n",
    "            previous_years = [y for y in coach_years[next_year_coach] if y < year]\n",
    "            if previous_years:\n",
    "                most_recent_year = max(previous_years)\n",
    "                current_year_cer = coach_cer_dict.get((next_year_coach, most_recent_year))\n",
    "        \n",
    "        if current_year_cer is None:\n",
    "            # If still no CER (rookie coach), use year average\n",
    "            current_year_cer = yearly_avg_cer.get(year)\n",
    "    \n",
    "    # Get next year's players and their PIE values\n",
    "    players_next_year = players_teams[\n",
    "        (players_teams['tmID'] == team) & (players_teams['year'] == next_year)\n",
    "    ]\n",
    "    \n",
    "    avg_pie = None\n",
    "    if not players_next_year.empty:\n",
    "        player_ids = players_next_year['playerID'].unique()\n",
    "        team_pies = []\n",
    "        \n",
    "        for pid in player_ids:\n",
    "            pie = None\n",
    "            \n",
    "            # Try to get current year PIE\n",
    "            pie_key = (pid, year)\n",
    "            pie = pie_dict.get(pie_key)\n",
    "            \n",
    "            if pie is None and pid in player_years:\n",
    "                # If no current year PIE, find the most recent previous PIE\n",
    "                previous_years = [y for y in player_years[pid] if y < year]\n",
    "                if previous_years:\n",
    "                    most_recent_year = max(previous_years)\n",
    "                    pie = pie_dict.get((pid, most_recent_year))\n",
    "            \n",
    "            if pie is None:\n",
    "                # If still no PIE (rookie), use year average\n",
    "                pie = yearly_avg_pie.get(year)\n",
    "            \n",
    "            if pie is not None:\n",
    "                team_pies.append(pie)\n",
    "        \n",
    "        if team_pies:\n",
    "            avg_pie = sum(team_pies) / len(team_pies)\n",
    "    \n",
    "    # Update the dataset\n",
    "    dataset.loc[index, 'AvgPIE_NextYearPlayers'] = avg_pie\n",
    "    dataset.loc[index, 'CER_NextYearCoach'] = current_year_cer\n",
    "\n",
    "# Convert columns to float type for consistency\n",
    "dataset['AvgPIE_NextYearPlayers'] = dataset['AvgPIE_NextYearPlayers'].astype(float)\n",
    "dataset['CER_NextYearCoach'] = dataset['CER_NextYearCoach'].astype(float)\n",
    "\n",
    "# First get the earliest year for each team to identify rookie seasons\n",
    "team_first_years = dataset.groupby('Team')['Year'].min()\n",
    "rookie_teams_data = dataset[dataset.apply(lambda x: x['Year'] == team_first_years[x['Team']], axis=1)]\n",
    "\n",
    "# Calculate average values for rookie teams\n",
    "rookie_averages = rookie_teams_data.mean(numeric_only=True)\n",
    "\n",
    "# Create new row for TUL\n",
    "new_team_row = pd.Series(rookie_averages)\n",
    "new_team_row['Team'] = 'TUL'\n",
    "new_team_row['Year'] = 10\n",
    "\n",
    "# Add the new row to the dataset\n",
    "dataset = pd.concat([dataset, pd.DataFrame([new_team_row])], ignore_index=True)\n",
    "\n",
    "# Sort dataset by Team and Year for clarity\n",
    "dataset = dataset.sort_values(['Team', 'Year'])\n",
    "\n",
    "display(dataset.head())\n",
    "\n",
    "# Filter the dataset for year 10\n",
    "year_10_data = dataset[dataset['Year'] == 10]\n",
    "\n",
    "# Save the filtered data to a CSV file\n",
    "output_file_path = './cleaned_data/year_10_stats.csv'  # Modify the path if needed\n",
    "year_10_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Year 10 stats saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label\n",
    "teams = teams.sort_values(by=['tmID', 'year']).reset_index(drop=True)\n",
    "dataset['PlayoffNextSeason'] = teams.groupby('tmID')['playoff'].shift(-1)\n",
    "dataset = dataset.dropna(subset=['PlayoffNextSeason'])\n",
    "dataset['PlayoffNextSeason'] = dataset['PlayoffNextSeason'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlayoffNextSeason\n",
       "1    71\n",
       "0    51\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PlayoffNextSeason\n",
       "1    71\n",
       "0    71\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.drop(columns=['Team', 'Year'])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataset.drop(columns=['PlayoffNextSeason'])\n",
    "y = dataset['PlayoffNextSeason']\n",
    "\n",
    "display(y.value_counts())\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Verify the new class distribution after applying SMOTE\n",
    "display(y_resampled.value_counts())\n",
    "\n",
    "# Merge resampled data into a new DataFrame\n",
    "balanced_dataset = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "balanced_dataset['PlayoffNextSeason'] = y_resampled\n",
    "\n",
    "dataset = balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved to ./cleaned_data/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the new dataset to a CSV file\n",
    "output_file_path = './cleaned_data/dataset.csv'\n",
    "dataset.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed dataset saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load the teams_post data\\nteams_post = pd.read_csv(\"./data/teams_post.csv\")\\n\\n# Drop \\'lgID\\' column as it contains only \"WNBA\" for every row\\nteams_post = teams_post.drop(columns=[\\'lgID\\'])\\n\\n# Detect and drop duplicates\\nduplicates = teams_post[teams_post.duplicated()]\\nif not duplicates.empty:\\n    print(\"Duplicates detected. Removing duplicate rows.\")\\n    teams_post = teams_post.drop_duplicates()\\nelse:\\n    print(\"No duplicates found.\")\\n\\n# Display a sample of the dataframe to verify changes\\ndisplay(teams_post.head())\\n\\n# Store cleaned csv\\nteams_post.to_csv(\\'./cleaned_data/teams_post.csv\\', index=False)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load the teams_post data\n",
    "teams_post = pd.read_csv(\"./data/teams_post.csv\")\n",
    "\n",
    "# Drop 'lgID' column as it contains only \"WNBA\" for every row\n",
    "teams_post = teams_post.drop(columns=['lgID'])\n",
    "\n",
    "# Detect and drop duplicates\n",
    "duplicates = teams_post[teams_post.duplicated()]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates detected. Removing duplicate rows.\")\n",
    "    teams_post = teams_post.drop_duplicates()\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# Display a sample of the dataframe to verify changes\n",
    "display(teams_post.head())\n",
    "\n",
    "# Store cleaned csv\n",
    "teams_post.to_csv('./cleaned_data/teams_post.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load the series_post data\\nseries_post = pd.read_csv(\"./data/series_post.csv\")\\n\\n# Drop \\'lgIDWinner\\' and \\'lgIDLoser\\' columns as they contain only \"WNBA\" and add no value\\nseries_post = series_post.drop(columns=[\\'lgIDWinner\\', \\'lgIDLoser\\'])\\n\\n# Detect and drop duplicates\\nduplicates = series_post[series_post.duplicated()]\\nif not duplicates.empty:\\n    print(\"Duplicates detected. Removing duplicate rows.\")\\n    series_post = series_post.drop_duplicates()\\nelse:\\n    print(\"No duplicates found.\")\\n\\n# Display a sample of the dataframe to verify changes\\ndisplay(series_post.head())\\n\\n# Store cleaned csv\\nseries_post.to_csv(\\'./cleaned_data/series_post.csv\\', index=False)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load the series_post data\n",
    "series_post = pd.read_csv(\"./data/series_post.csv\")\n",
    "\n",
    "# Drop 'lgIDWinner' and 'lgIDLoser' columns as they contain only \"WNBA\" and add no value\n",
    "series_post = series_post.drop(columns=['lgIDWinner', 'lgIDLoser'])\n",
    "\n",
    "# Detect and drop duplicates\n",
    "duplicates = series_post[series_post.duplicated()]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates detected. Removing duplicate rows.\")\n",
    "    series_post = series_post.drop_duplicates()\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# Display a sample of the dataframe to verify changes\n",
    "display(series_post.head())\n",
    "\n",
    "# Store cleaned csv\n",
    "series_post.to_csv('./cleaned_data/series_post.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Aggregate data by coachID and year (ignoring stint and tmID)\\ncoaches_agg = coaches.groupby(['coachID', 'year']).agg({\\n    'won': 'sum',\\n    'lost': 'sum',\\n    'post_wins': 'sum',\\n    'post_losses': 'sum'\\n}).reset_index()\\n\\n# Preview the aggregated data\\nprint(coaches_agg.head())\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Aggregate data by coachID and year (ignoring stint and tmID)\n",
    "coaches_agg = coaches.groupby(['coachID', 'year']).agg({\n",
    "    'won': 'sum',\n",
    "    'lost': 'sum',\n",
    "    'post_wins': 'sum',\n",
    "    'post_losses': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Preview the aggregated data\n",
    "print(coaches_agg.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Find the coach with the maximum post_wins for each year\\nmax_post_wins_per_year = coaches_agg.loc[coaches_agg.groupby('year')['post_wins'].idxmax()][['year', 'coachID', 'post_wins']]\\nmax_post_wins_per_year = max_post_wins_per_year.rename(columns={'post_wins': 'max_post_wins'})\\n\\n# Merge this information back with the original DataFrame\\ncoaches_agg = coaches_agg.merge(max_post_wins_per_year, on=['year', 'coachID'], how='left')\\n\\n# Set the championship indicator\\ncoaches_agg['championship'] = 0\\ncoaches_agg.loc[coaches_agg.set_index(['year', 'coachID']).index.isin(max_post_wins_per_year.set_index(['year', 'coachID']).index) & (coaches_agg['post_wins'] >= 6), 'championship'] = 1\\n\\n# Drop the temporary max_post_wins column\\ncoaches_agg.drop(columns=['max_post_wins'], inplace=True)\\n\\n# Recalculate metrics\\ncoaches_agg['win_ratio'] = (coaches_agg['won'] / (coaches_agg['won'] + coaches_agg['lost'])).round(4)\\ncoaches_agg['post_win_ratio'] = (coaches_agg['post_wins'] / (coaches_agg['post_wins'] + coaches_agg['post_losses'])).round(4)\\n\\n# If a coach has not reached playoffs, post_win% will be NaN. Fill these with 0.\\ncoaches_agg['post_win_ratio'] = coaches_agg['post_win_ratio'].fillna(0)\\n\\n# Merge with Awards Data for Coach of the Year\\ncoaches_agg = coaches_agg.merge(\\n    coach_awards[['coachID', 'year', 'award']], \\n    on=['coachID', 'year'], \\n    how='left'\\n)\\ncoaches_agg['COTY'] = np.where(coaches_agg['award'] == 'Coach of the Year', 1, 0)\\ncoaches_agg.drop(columns=['award', 'won', 'lost'], inplace=True)\\n\\n#Normalize features if needed\\ncoaches_agg['win_ratio'] = coaches_agg['win_ratio'].clip(0, 1)  # Ensure the ratio is between 0 and 1\\ncoaches_agg['post_win_ratio'] = coaches_agg['post_win_ratio'].clip(0, 1)  # Ensure the ratio is between 0 and 1\\n\\n# Drop the temporary columns\\ncoaches_agg.drop(columns=['post_wins', 'post_losses'], inplace=True)\\n\\n# Preview updated data\\nprint(coaches_agg.head())\\n\\n# Store cleaned csv\\ncoaches_agg.to_csv('./cleaned_data/coaches_agg.csv', index=False)\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Find the coach with the maximum post_wins for each year\n",
    "max_post_wins_per_year = coaches_agg.loc[coaches_agg.groupby('year')['post_wins'].idxmax()][['year', 'coachID', 'post_wins']]\n",
    "max_post_wins_per_year = max_post_wins_per_year.rename(columns={'post_wins': 'max_post_wins'})\n",
    "\n",
    "# Merge this information back with the original DataFrame\n",
    "coaches_agg = coaches_agg.merge(max_post_wins_per_year, on=['year', 'coachID'], how='left')\n",
    "\n",
    "# Set the championship indicator\n",
    "coaches_agg['championship'] = 0\n",
    "coaches_agg.loc[coaches_agg.set_index(['year', 'coachID']).index.isin(max_post_wins_per_year.set_index(['year', 'coachID']).index) & (coaches_agg['post_wins'] >= 6), 'championship'] = 1\n",
    "\n",
    "# Drop the temporary max_post_wins column\n",
    "coaches_agg.drop(columns=['max_post_wins'], inplace=True)\n",
    "\n",
    "# Recalculate metrics\n",
    "coaches_agg['win_ratio'] = (coaches_agg['won'] / (coaches_agg['won'] + coaches_agg['lost'])).round(4)\n",
    "coaches_agg['post_win_ratio'] = (coaches_agg['post_wins'] / (coaches_agg['post_wins'] + coaches_agg['post_losses'])).round(4)\n",
    "\n",
    "# If a coach has not reached playoffs, post_win% will be NaN. Fill these with 0.\n",
    "coaches_agg['post_win_ratio'] = coaches_agg['post_win_ratio'].fillna(0)\n",
    "\n",
    "# Merge with Awards Data for Coach of the Year\n",
    "coaches_agg = coaches_agg.merge(\n",
    "    coach_awards[['coachID', 'year', 'award']], \n",
    "    on=['coachID', 'year'], \n",
    "    how='left'\n",
    ")\n",
    "coaches_agg['COTY'] = np.where(coaches_agg['award'] == 'Coach of the Year', 1, 0)\n",
    "coaches_agg.drop(columns=['award', 'won', 'lost'], inplace=True)\n",
    "\n",
    "#Normalize features if needed\n",
    "coaches_agg['win_ratio'] = coaches_agg['win_ratio'].clip(0, 1)  # Ensure the ratio is between 0 and 1\n",
    "coaches_agg['post_win_ratio'] = coaches_agg['post_win_ratio'].clip(0, 1)  # Ensure the ratio is between 0 and 1\n",
    "\n",
    "# Drop the temporary columns\n",
    "coaches_agg.drop(columns=['post_wins', 'post_losses'], inplace=True)\n",
    "\n",
    "# Preview updated data\n",
    "print(coaches_agg.head())\n",
    "\n",
    "# Store cleaned csv\n",
    "coaches_agg.to_csv('./cleaned_data/coaches_agg.csv', index=False)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
